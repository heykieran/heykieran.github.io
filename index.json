[{"authors":["heykieran"],"categories":null,"content":"Kieran Owens is the CTO of Timpson Gray\n","date":1590659384,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1590659384,"objectID":"1b59167ee93fdb1982478d476b8e75dd","permalink":"https://heykieran.github.io/author/kieran-owens/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/kieran-owens/","section":"authors","summary":"Kieran Owens is the CTO of Timpson Gray","tags":null,"title":"Kieran Owens","type":"authors"},{"authors":["admin"],"categories":null,"content":"Nelson Bighetti is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://heykieran.github.io/author/nelson-bighetti/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/nelson-bighetti/","section":"authors","summary":"Nelson Bighetti is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.","tags":null,"title":"Nelson Bighetti","type":"authors"},{"authors":["Kieran Owens"],"categories":["Blog Post"],"content":"Introduction In a previous blog post I showed how it was possible to take a Clojure project containing a Pedestal back-end and a React front-end, and package it as a Docker container which can be run as a standalone Docker image using docker run, or as part of a Docker Swarm using docker service. In this post, I will show how it is possible to deploy the same Docker container to a Kubernetes Cluster and to make the application available at a particular URL of your choosing.\nSummary of the steps  Create a GCP Project Build and Tag your Docker image Upload your image to the Google Registry Create a GKE Cluster Get a Google Static IP address Create an A record in your DNS for the IP endpoint Create a Google managed SSL certificate Deploy your image to the cluster Create a back-end service over your container Create an Ingress front-end service connecting the external IP address to the back-end service over https  The Steps Setting up a Cloud Project on GCP Before you start, you\u0026rsquo;ll need to create a Google Cloud Project. This is a simple process, so I won\u0026rsquo;t go into the details as instructions can be found here.\n The current demo assumes that the project name is clojure-app-v1, that a Docker daemon is running locally, and that the docker binary is on your path. Also, the URL at which the application is published is chosen to be https://demo.timpsongray.com. Obviously, this will be different for you.\n You should also install both the gcloud and kubectl command line tools locally. If this is your first GCP project, don\u0026rsquo;t forget to also initialize the Cloud SDK. This will set your account\u0026rsquo;s credentials, authorize access to GCP API\u0026rsquo;s, and establish a base configuration, such as your default compute region and zone.\n  Installing gcloud  Initializing the SDK  Once you have installed gcloud locally, installing kubectl is simply a matter of running\n$ gcloud components install kubectl  from the command line.\nFinally, with the tools installed and your project created, you can view its details using\n$ gcloud projects describe clojure-app-v1  Setting your Current Project Now, you should set clojure-app-v1 to be the current project. (If you\u0026rsquo;ve run gcloud init as above, this should already have been done, but it\u0026rsquo;s no harm to set it a second time.)\n$ gcloud config set project clojure-app-v1  Connecting you Docker Repository to GCP In order to easily publish a docker image from your local machine to a GCP container registry you should configure docker to use gcloud as the credential helper for all Google\u0026rsquo;s registries using\n$ gcloud auth configure-docker  Build and Tag the docker image Build the docker image If your using the repo, you can do this by issuing\n$ make clean-all $ make docker  from the command line.\nTag the image for upload to the Google container registry Now we\u0026rsquo;ll tag the image so it conforms with the image names expected by the Google registry.\n$ docker tag clojure-app-v1 gcr.io/clojure-app-v1/clojure-app-v1   By default, the above command adds :latest to the end of the tag.\n The Google registry location is constructed using gcr.io/\u0026lt;PROJECT_NAME\u0026gt;/\u0026lt;IMAGE_NAME\u0026gt;.\nIn the current situation the PROJECT_ID and the IMAGE_NAME are the same, but this does not always have to be the case.\nPush the image to the Google Registry Before Google will accept a pushed image you need to enable the Google Container Registry API for your project\n$ gcloud services enable containerregistry.googleapis.com  and then push the tagged image using\n$ docker push gcr.io/clojure-app-v1/clojure-app-v1  Create the Cluster First enable the Kubernetes Engine API using\n$ gcloud services enable container.googleapis.com  which may take a few minutes.\nWhen complete, we ask GKE to create a cluster with a single node, which is sufficient for illustrative purposes.\n$ gcloud container clusters create cluster-clojure-app-v1 --num-nodes=1  Again, this may take a few minutes as the cluster\u0026rsquo;s resources are created, deployed and health-checked.\nImport Credentials Once the cluster has been created we sync credentials\n$ gcloud container clusters get-credentials cluster-clojure-app-v1  This will create a kubeconfig entry for the cluster, and allow you to manage the new cluster using the kubectl command line tool.\nGet a static IP address for your site We have decided to publish our application at a well-known url (i.e. demo.timpsongray.com), so we need to ensure that we have a stable, externally addressable IP address. We do this by asking GCP to assign a global IP address for our use.\n$ gcloud compute addresses create clojure-app-v1-addr --global  Find the external IP address Now, find what IP address was assigned using\n$ gcloud compute addresses list  which should return something like\nNAME ADDRESS/RANGE TYPE PURPOSE NETWORK REGION SUBNET STATUS clojure-app-v1-addr 34.107.182.232 EXTERNAL RESERVED  Make a note of the IP address, and then add an A record to your DNS associating the name demo.timpsongray.com with that IP address. You may need to wait a little while for the DNS changes to propogate.\nCreate a Secret The application uses either environment variables or docker secrets to configure itself. From an internal perspective, this distinction is abstracted away with the use of the walmartlabs/dyn-edn Clojure library.\nHowever, GKE adds a feature to its use of secrets that is not available with docker swarm - it\u0026rsquo;s possible to have a secret\u0026rsquo;s value dynamically injected into a container\u0026rsquo;s environment as a standard environment variable.\nIn order to make use of this, of course, you must create a secret. This can be done as follows. (The value of \u0026lt;THESECRET\u0026gt; should be the password for the keystore used by the Jetty instance in your application).\n$ kubectl create secret generic demo-secrets \\ --from-literal=ALLOC_KEYSTORE_PASSWORD='\u0026lt;THESECRET\u0026gt;'  You can check that the secret was created successfully by issuing the following command and inspecting the results\n$ kubectl describe secrets/demo-secrets  Deploy your App to the Cluster Now deploy the Docker image containing the application to a container running in the cluster specifying the image recently pushed to the Google registry.\nDuring the deployment GKE will be requested to inject the value of the ALLOC_KEYSTORE_PASSWORD from the demo-secrets resource as an environment variable (also called ALLOC_KEYSTORE_PASSWORD) into the container\u0026rsquo;s run-time environment. This variable is used by the Clojure application to gain access to Jetty\u0026rsquo;s keystore, which is required to allow Jetty to publish the application on an https endpoint.\n Kubernetes secrets can also be made available within the container at a particular mount point (using tmpfs). This is similar to Docker swarm\u0026rsquo;s strategy. We could use it here, but the environment variable approach is simpler and the use of the dyn-edn library ensures that there\u0026rsquo;s very little transition to be done moving from a local development environment and the Kubernetes production environment.   Now instruct GKE to deploy the application using\n$ kubectl apply -f deploy.yaml  where the contents of the deploy.yaml file is as follows\napiVersion: apps/v1 kind: Deployment metadata: labels: app: demo name: demo-web spec: replicas: 1 selector: matchLabels: app: demo tier: web template: metadata: labels: app: demo tier: web spec: containers: - image: gcr.io/clojure-app-v1/clojure-app-v1:latest name: demo-app ports: - containerPort: 8081 env: - name: ALLOC_KEYSTORE_PASSWORD valueFrom: secretKeyRef: name: demo-secrets key: ALLOC_KEYSTORE_PASSWORD  Create a Back-End Service To access the deployed application GKE is requested to create a back-end service over the pods containing the deployment. The request will be for a NodePort service, which exposes the Service on the same port of each selected Node in the cluster using NAT. Makes a Service accessible from outside the cluster using :. Superset of ClusterIP.\nThis is done using\n$ kubectl apply -f service.yaml  where the content of the service.yaml file is as follows\napiVersion: v1 kind: Service metadata: name: demo-svc annotations: cloud.google.com/app-protocols: '{\u0026quot;app-https-port\u0026quot;:\u0026quot;HTTPS\u0026quot;,\u0026quot;app-http-port\u0026quot;:\u0026quot;HTTP\u0026quot;}' labels: app: demo spec: type: NodePort selector: app: demo tier: web ports: - name: app-https-port port: 8081 targetPort: 8081 - name: app-http-port port: 8080 targetPort: 8080   Why http? (and other notes on Health Checks) GKE will automatically create Health Checks to check the status of the backend services created, and which expose your deployment.\nBy default, for web services, GKE will probe the app at a particular path (/ or /healthz) using a particular protocol (http or https).\nNetwork load balancers require legacy health checks. These must be http, which means that the backend must support http probing by the health checking mechanisms. Don\u0026rsquo;t disable http on NodePort service (the backend service) or GKE will complain.\n Although Legacy health checks can be https, the Network Load Balancer only supports http.\n   Check the Service\u0026rsquo;s Status A convenient way to check if a web application is running correctly is to use port forwarding from your local machine to tunnel directly to the running pod. You can use the following command to open a tunnel to the node\u0026rsquo;s port 8081 (which is the home port for the containerized Clojure application) from port 8080 on localhost.\n$ gcloud container clusters get-credentials \\ cluster-clojure-app-v1 --zone us-east4-a --project clojure-app-v1 \\ \u0026amp;\u0026amp; kubectl port-forward $(kubectl get pod \\ --selector=\u0026quot;app=demo,tier=web\u0026quot; \\ --output jsonpath='{.items[0].metadata.name}') 8080:8081  and then in your browser, navigate to https://localhost:8080.\nIf everything is operating correctly, you should see the home page of the Clojure application served by Jetty.\nIn your console window type Ctrl+C to stop port forwarding.\nSet up External Routing In the following section we will connect our chosen URL demo.timpsongray.com to the application.\nBut first we\u0026rsquo;ll need to perform a few checks and actions.\nCheck that the app\u0026rsquo;s DNS name is available From the command line run\n$ nslookup demo.timpsongray.com  and ensure that the address returned is the static IP address that was created by Google earlier. This indicates that the DNS is responding correctly.\nCreate a Google Managed SSL Certificate We want to use https on our publicly accessible endpoint so we\u0026rsquo;ll need to install an SSL certificate. There are a few ways to do this, but the most convenient is to use GCP\u0026rsquo;s managed SSL certificates.\n DNSSEC\nIn order for the managed certicate creation to happen correctly, and for the external IP address you provisioned to be associated with it (when you create the Ingress service), DNSSEC must be enabled on your domain and the A record you created on the domain must point to the static IP address.\nIf either of these aren\u0026rsquo;t set correctly, you may see a Status: FailedNotVisible status when you issue the kubectl describe managedcertificate command below, and the Ingress creation will fail.\n  We can request a managed SSL certificate using\n$ kubectl apply -f cert.yaml  where the content of the cert.yaml file is\napiVersion: networking.gke.io/v1beta1 kind: ManagedCertificate metadata: name: demo-app-cert spec: domains: - demo.timpsongray.com  Check the status of the SSL certificate We can check the status of the SSL provisioning process using\n$ gcloud compute ssl-certificates list --global  which will show something like\nNAME TYPE CREATION_TIMESTAMP EXPIRE_TIME MANAGED_STATUS mcrt-5fc3491d-21fc-4dda-8eb3-6f1b91545247 MANAGED 2020-05-28T06:38:28.757-07:00 PROVISIONING demo.timpsongray.com: PROVISIONING  indicating that provisioning has started, and that the URL is as expected.\nCreate an Ingress Front-End Service In order to connect the outside world with the back-end service we will create load-balanced Ingress service using\n$ kubectl apply -f ingress.yaml  where the content of the ingress.yaml file is\napiVersion: networking.k8s.io/v1beta1 kind: Ingress metadata: name: demo-web annotations: kubernetes.io/ingress.global-static-ip-name: \u0026quot;clojure-app-v1-addr\u0026quot; kubernetes.io/ingress.allow-http: \u0026quot;false\u0026quot; networking.gke.io/managed-certificates: \u0026quot;demo-app-cert\u0026quot; labels: app: demo spec: backend: serviceName: demo-svc servicePort: 8081  Although the kubectl command returns quickly it can take a few minutes for the ingress to be provisioned, deployed and stabilized. You can check its status using\n$ kubectl describe ingress demo-web  When the provisioning is completed, you should be able to navigate to https://demo.timpsongray.com and view your application.\nViewing Logs Kubernetes allows you to inspect the logs of the Clojure application if you specify the pod in which it\u0026rsquo;s running. In order to discover the pod name you can issue the following command\n$ kubectl get pods  which will return something like\nNAME READY STATUS RESTARTS AGE demo-web-966bb64f7-zfrdh 1/1 Running 0 68m  You can then issue the following command (substituting the correct pod name) to view the application logs\n$ kubectl logs demo-web-966bb64f7-zfrdh  Closure Deploying a web application to Kubernetes and exposing it on the web with a specific URL isn\u0026rsquo;t particularly difficult, but there are a number of places where things can go pear-shaped. Hopefully, this will help when you try to do the same thing.\n","date":1590659384,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590659384,"objectID":"16016e5b63860e4d20373718f4684f5a","permalink":"https://heykieran.github.io/post/deploy-to-kubernetes-gke/","publishdate":"2020-05-28T05:49:44-04:00","relpermalink":"/post/deploy-to-kubernetes-gke/","section":"post","summary":"I will show you how to deploy a packaged application comprising a Clojure Pedestal API server and a ClojureScript (reagent/reframe) front-end React application to a Kubernetes Cluster running on GKE (Google), and how to make it available externally at a specific URL.","tags":["clojure","deployment","kubernetes","GKE"],"title":"Deploy a Clojure Web Application to Kubernetes (GKE)","type":"post"},{"authors":["Kieran Owens"],"categories":["Blog Post"],"content":"Introduction In this post I\u0026rsquo;ll show how to build and deploy to docker a fully-functioning application comprising a secure Pedestal API web-server and a React front-end application written in ClojureScript which accesses the server.\nFor this example I\u0026rsquo;ll be using the Pedestal/React application I previously discussed in this blog post (with its code here).\nOutline of the Steps I\u0026rsquo;ll set up a working directory for the build, clone the target application into a sub-directory, compile the target, package it and its dependencies to java byte code, assemble them into a jar, create a docker image for the application, and deploy it as a docker service.\nBackground, Challenges \u0026amp; Tools During this exercise, I\u0026rsquo;ll try to keep separate the application I\u0026rsquo;m building from the application doing the building. This isn\u0026rsquo;t strictly necessary but it will help illustrate a procedure generally applicable to any Clojure application.\nOne of the challenges of this approach is that I\u0026rsquo;ll need to deal with two deps.edn files - one for the build environment and one for the application being built. Each deps file contains relative paths (:paths and :extra-paths) relative to the root of the project directory to which it belongs.\nIf I am to avoid changing in any way the deps file for the project being built and yet still ensure that the built artifacts end up in the correct location within the build project\u0026rsquo;s directory structure I will need a way to inform the compiler about which paths to use, but relative to the build project\u0026rsquo;s directory and not as specified in the target\u0026rsquo;s deps.edn file.\nAs an example, let\u0026rsquo;s suppose that the build project is at ./clj-deploy-docker and the project being built will be cloned into ./clj-deploy-docker/target-app.\nThe deps.edn file in ./clj-deploy-docker/target-app will contain an entry for the alias :main as below\n:aliases {:main {:paths [\u0026quot;src\u0026quot;] :extra-deps {ch.qos.logback/logback-classic {:mvn/version \u0026quot;1.2.3\u0026quot;} org.clojure/tools.logging {:mvn/version \u0026quot;0.4.1\u0026quot;} ring/ring-core {:mvn/version \u0026quot;1.8.0\u0026quot;} ring/ring-jetty-adapter {:mvn/version \u0026quot;1.8.0\u0026quot;} ring/ring-devel {:mvn/version \u0026quot;1.8.0\u0026quot;} io.pedestal/pedestal.service {:mvn/version \u0026quot;0.5.7\u0026quot;} io.pedestal/pedestal.route {:mvn/version \u0026quot;0.5.7\u0026quot;} io.pedestal/pedestal.jetty {:mvn/version \u0026quot;0.5.7\u0026quot;} buddy {:mvn/version \u0026quot;2.0.0\u0026quot;} hiccup {:mvn/version \u0026quot;1.0.5\u0026quot;} org.conscrypt/conscrypt-openjdk-uber {:mvn/version \u0026quot;2.2.1\u0026quot;} org.eclipse.jetty/jetty-alpn-conscrypt-server {:mvn/version \u0026quot;9.4.24.v20191120\u0026quot;} com.google.api-client/google-api-client {:mvn/version \u0026quot;1.30.6\u0026quot;} com.walmartlabs/dyn-edn {:git/url \u0026quot;https://github.com/walmartlabs/dyn-edn.git\u0026quot; :sha \u0026quot;855a775959cf1bec531a303a323e6f05f7b260fb\u0026quot;}} :extra-paths [\u0026quot;resources\u0026quot; \u0026quot;common-src\u0026quot; ]}  In order to access and use this alias correctly from the build project\u0026rsquo;s directory (clj-deploy-docker) I will need to adjust (in some way) the paths so that the compiler is operating with the correct class path i.e. the class path of the target rather than the class path of the build. Therefore, I\u0026rsquo;ll need to let the compiler know (in some way) that the :paths and :extra-paths vectors should read\n:paths [\u0026quot;target-app/src\u0026quot;]  and\n:extra-paths [\u0026quot;target-app/resources\u0026quot; \u0026quot;target-app/common-src\u0026quot; ]  respectively.\n On the other hand, the maven coordinates in the target\u0026rsquo;s deps.edn file are correct, so we can leave the :deps and :extra-deps values as they are found.\n As for the \u0026ldquo;in some way\u0026rdquo;, I will be using the Badigeon library to achieve this. Many of Badigeon\u0026rsquo;s API\u0026rsquo;s take a :deps-map as input. This is an in-memory map whose structure is the same as a deps.edn file. This will allow me to read the deps file, make in-memory adjustments and feed it to to API to do the bundling and compiling with a classpath relative to any directory I choose (i.e. relative to ./clj-deploy-docker).\nCreate a Working Directory for the Project Create a working directory for the project, and cd into it\n$ mkdir clj-deploy-docker $ cd clj-deploy-docker  Setting up the Application to be built Now, I\u0026rsquo;ll clone the repository of the application I want to build into a directory target-app under my working directory.\n$ git clone https://github.com/heykieran/clj-pedestal-google.git target-app  As mentioned above, for this exercise I will be using a library called Badigeon to organize and compile the sources. It leverages many of the tools \u0026amp; libraries already available in clojure.core and tools.deps; it\u0026rsquo;s very flexible and I find the API intuitive.\nCreating the build runner In my project\u0026rsquo;s working directory I create a deps.edn file.\n$ touch deps.edn  and add the Badigeon dependency to the deps.edn file.\n{:deps {} :aliases {:build {:extra-paths [\u0026quot;build\u0026quot;] :extra-deps {badigeon/badigeon {:git/url \u0026quot;https://github.com/EwenG/badigeon.git\u0026quot; :sha \u0026quot;1edf7ae465db870ec0066f28226edb9b04873b70\u0026quot; :tag \u0026quot;0.0.11\u0026quot;}}}}}  Apart from the Clojure system and user dependencies this is the only dependency I\u0026rsquo;ll need in that file.\nAlso, for later use, I create a directory called build to contain the Clojure files to run the bundling, compilation and assembling processes.\n$ mkdir build  Building the Front-End JS File As outlined in my previous blog post, the following command will build the front-end production application\u0026rsquo;s js file from the ClojureScript sources for the application being dockerized.\n$ cd target-app $ clj -A:prod $ cd ..  This will build the application\u0026rsquo;s front-end only and place the production js file (prod-main.js) in the target-app/target/public/cljs-out directory. This is the only change that will be made to the directories and files under target-app.\nAt a later stage I will move this file to its correct location under my project directory (./clj-deploy-docker) so that it can be included in the docker image.\nBuilding the Back-End (JVM) Class Files I\u0026rsquo;ll now cd into the build directory I created previously and create a package.clj file. This file will contain the -main method that ultimately performs the bundling, compilation and consolidation of the back-end Clojure files i.e. the JVM class files.\nSome Background on Bundling, Compilation and Consolidation (Jar\u0026lsquo;ing) There are three distinct phases to assembling the JVM artifacts to include in the docker image and I will be using the Badigeon API to perform all three phases.\n  Bundling The bundling step creates a \u0026ldquo;bundle\u0026rdquo; at a specified file-system location of all the target project\u0026rsquo;s resources and dependencies, including any jar files that are needed. Note that because the Badigeon bundler does not merge in the system and user deps preferences, it will not automatically copy sources that are in src directory of your project, unless that directory is explicitly specified in the :paths or :extra-paths entries in the deps.edn file. During the bundling phase all the jar files required by your application, and all other resources on the classpath such as static html file, css files, user authored js files etc. will be copied to the specified target directory.\n  Compilation During the compilation step the compiled versions of your Clojure source files (as .class files) are generated and copied to a specified target directory.\n  Consolidation The final phase involves creating a jar file containing all the .class files needed by the application with an appropriate manifest file (META-INF/MANIFEST.MF) which has an entry indicating the application\u0026rsquo;s entry-point (a Main-Class entry), and an entry specifying the libraries to be used by the jar file (a Class-Path entry).\n Dependencies (found by Badigeon using the :deps and :extra-deps coordinates) will not be incorporated into this jar file. They will however be added to a ./lib directory as individual jar files and referenced by the Class-Path entry in the jar\u0026rsquo;s manifest file.\n   Once these three phases are complete, and the js file containing the front-end application is placed in its correct location, the application can be run using the java command line tool.\nI\u0026rsquo;ll come to that presently, but first I\u0026rsquo;d like to take a slightly deeper look at the bundling, compilation and consolidation phases. The full details are available in the package.clj file from which the following code snippets have been extracted.\nNotes on the code performing the three steps First, I bundle\n(bundle out-path {:deps-map translated-deps-map :aliases aliases :libs-path \u0026quot;lib\u0026quot;})  Given a deps-map and a vector of aliases ([:main]) this function will copy the projects\u0026rsquo;s resources needed to out-path, and also copy the jar files required to out-path/lib. Because the code I want to bundle is in the target-app directory, I\u0026rsquo;ll read the deps.edn file from its location under target-app and update the :path and :extra-paths entries so that they are now relative to the current working directory rather than target-app (see above).\nNow the compilation phase runs:\n(compile/compile 'main.core {:compile-path classes-path :classpath (translate-path-to-absolute target-dir deps-map aliases)})  This compiles the main.core namespace, putting the .class files into the directory specified by the classes-path directory, using a classpath specified by the value of the :classpath entry. In my case, this is generated by reading the target-app/deps.edn file into deps-map and converting the relative components of :paths and :extra-paths vectors to absolute file-system locations.\nFinally, the consolidation phase runs:\n(spit manifest-path (jar/make-manifest 'main.core {:Class-Path (str \u0026quot;. \u0026quot; (str/join \u0026quot; \u0026quot; (mapv #(str \u0026quot;lib/\u0026quot; (.getName %)) (.listFiles (io/file \u0026quot;target/app/lib\u0026quot;)))))})) (zip/zip classes-path (str (make-path out-path \u0026quot;app-runner\u0026quot;) \u0026quot;.jar\u0026quot;))  This achieves two things:\n  It creates a manifest file in target/app/classes/META-INF, setting main.core as the entry point, and adds entries for all the jar files in the target/lib directory (which was created and populated during bundling) into the manifest file\u0026rsquo;s Class-Path header field. In order for the application to run there is an assumption that the final jar file and the lib directory will exist at the same level in the file system i.e. in the same directory.\n  It creates a app-runner.jar file from the contents of the target/app/classes directory. This jar file is the main application and will contain the manifest file just created with its Class-Path entry pointing to the non-application jar files it needs to run - i.e. those found in the lib directory.\n  In order to run all three steps, I can \u0026ldquo;execute\u0026rdquo; the package namespace passing the target-app directory name as an argument.\n$ clj -A:build -m package \u0026quot;target-app\u0026quot;  This completes the Bundling, Compilation and Consolidation steps, and when it finishes I will have a directory structure, which with the addition of the front-end js file (which I compiled above) will constitute the complete application.\nI can copy the js file to its correct location using\n$ mkdir -p target/app/public/cljs-out \u0026amp;\u0026amp; \\ cp target-app/target/public/cljs-out/prod-main.js \u0026quot;$_\u0026quot;  Now, everything I need (and some I don\u0026rsquo;t) is available in the ./target/app/ directory.\nRunning the Application Before running the compiled application I need to ensure that certain environment variables are defined and set correctly.\nAs discussed in my previous post, the application requires a number of environment variables to be set in order to configure itself correctly.\nThese are\n# the https port number used by the Pedestal API server ALLOC_SSL_PORT=8081 # the password of Jetty's keystore ALLOC_KEYSTORE_PASSWORD=\u0026lt;password\u0026gt; # the http port number used by the Pedestal API server ALLOC_PORT=8080 # the file system location of the Jetty's keystore (as an absolute file path) ALLOC_KEYSTORE_LOCATION=\u0026lt;location\u0026gt;  I can cd into the built artifact\u0026rsquo;s directory (./target/app) and run the backend application directly from the jar file\n$ cd target/app $ java -jar app-runner.jar  or, because the classes still exist in a classes directory under the app directory\n$ cd target/app $ java -cp .:classes:lib/* main.core  The app will start, and when it\u0026rsquo;s fully initialized, I can navigate to https://localhost:8081/r/home to see it in action.\n There is also a lot of unnecessary \u0026ldquo;residue\u0026rdquo; in the ./target/app directory, created during bundling, including directories containing clj and cljc files that are not actually needed to run the application (they will already have been compiled into the classes directory).\n When I process the files for deployment to docker, these will be removed.\nThere remains then only the task of creating the docker image itself, which is outlined below.\nCreate the Docker Image The docker image I will use is very simple - a basic Debian stretch image with a Java8 SDK.\nIn my project directory I create a directory called docker and cd into it.\n$ mkdir docker $ cd docker  and create a Dockerfile containing\nFROM openjdk:8-stretch COPY entrypoint.sh /sbin/entrypoint.sh RUN chmod 755 /sbin/entrypoint.sh EXPOSE 8081/tcp COPY deploy /image WORKDIR /image/app ENV ALLOC_KEYSTORE_LOCATION=/image/local/jetty-keystore \\ ALLOC_KEYSTORE_PASSWORD=password \\ ALLOC_PORT=8080 \\ ALLOC_SSL_PORT=8081 ENTRYPOINT [\u0026quot;/sbin/entrypoint.sh\u0026quot;]  The Dockerfile as defined will\n create an image from a base openjdk:8-stretch image, copy the file entrypoint.sh (which I haven\u0026rsquo;t created yet) from the docker/deploy folder to the image\u0026rsquo;s /sbin directory and set its mode to executable, enable network connectivity to port 8081 only (there will be no access to the unprotected http port 8080), copy the entire contents of the docker/deploy directory to the image\u0026rsquo;s /image directory, set the image\u0026rsquo;s working directory to /image/app, set the needed environment variables for the new image, and specify that the /sbin/entrypoint.sh script should be run when the container starts.  The deploy directory under the docker directory is the location where the application\u0026rsquo;s artifact will be assembled before their inclusion in the image when the COPY deploy /image command is run.\nFrom my project\u0026rsquo;s folder (clj-deploy-docker) I run the following command to copy the entire app (including residue) to the docker/deploy folder (creating it if it doesn\u0026rsquo;t exist).\n$ mkdir -p docker/deploy/app \u0026amp;\u0026amp; cp -r target/app/* \u0026quot;$_\u0026quot;  Now, in order to remove the extraneous files I can run\n$ find docker/deploy/app -maxdepth 1 -mindepth 1 -type d \\( ! \\( -name 'lib' -o -name 'public' \\) \\) -exec rm -rf {} \\;  This deletes any sub-directory in the docker/deploy folder not named lib (which contain the jar files the application needs) or public (which contains all the non-JVM resources the application needs).\nI now add the entrypoint.sh file to the docker/deploy folder. This script, which is run when the image is started, simply calls the application\u0026rsquo;s entry-point.\n#!/bin/bash # exit immediately if error set -e java -jar app-runner.jar  Finally, I need to ensure that the keystore used to encrypt the application\u0026rsquo;s https communication is available for the image build process, so I copy it from my local file system\u0026rsquo;s location to the /docker/deploy/local directory, from whence, during the image building process, it will be copied to the image\u0026rsquo;s /image/local folder.\n# mkdir -p docker/deploy/local \u0026amp;\u0026amp; cp \u0026lt;location-of-keystore\u0026gt; \u0026quot;$_\u0026quot;  Now, with everything cleaned-up and with the script and the keystore in place, I can create the application\u0026rsquo;s docker image, tagging it with the label testapp:dev.\n$ docker build -t testapp:dev docker  and then run a container based on that image using\n$ docker run --rm --name test --env ALLOC_KEYSTORE_PASSWORD=\u0026lt;the-real-keystore-password\u0026gt; -p:8081:8081 -it testapp:dev  I can then open my browser to https://localhost:8081/r/home in order to confirm it\u0026rsquo;s running correctly.\n Note When I created the image I did not include the correct password for the keystore in the Dockerfile. Therefore, in order for the application to work correctly I\u0026rsquo;m required to pass the correct value by setting the env variable ALLOC_KEYSTORE_PASSWORD when I start the container. It will be used in lieu of the value embedded in the image.\n Docker Secrets Passing sensitive information using environment variables is satisfactory in many situations, but there is available a better approach: docker secrets.\n Note Docker secrets are not available in stand-alone mode, the feature is only available in swarm mode.\n Passing Configuration Values For further details on the subject of passing configurations to a Clojure application you can refer to my blog post on the subject. The post also discusses more fully the mechanics of how the configuration is used by the application\u0026rsquo;s code.\nCreate a swarm To create a local swarm for testing I can issue the following command\n$ docker swarm init  Once the swarm has been initialized I can add a secret to the registry. Let\u0026rsquo;s suppose I want to protect the ALLOC_KEYSTORE_PASSWORD and avoid having to pass it to the image as an environment variable. I can simply create a docker secret to hold the value, protecting it from being stolen too easily. The following command will create a secret called ALLOC_KEYSTORE_PASSWORD, set its value to MYKEYSTOREPASSWORD and store it in the swarm\u0026rsquo;s registry.\n$ printf \u0026quot;MYKEYSTOREPASSWORD\u0026quot; | docker secret create ALLOC_KEYSTORE_PASSWORD -  You can test that the secret was successfully created by issuing\n$ docker secret ls  In order to use the secret, the container has to be started as a service within the swarm, and on the command line must be specified to what secrets the service has access. In order to start the container with access to the ALLOC_KEYSTORE_PASSWORD and linking swarm\u0026rsquo;s network to the host\u0026rsquo;s network I can issue the following command\n$ docker service create --replicas 1 \\ --secret ALLOC_KEYSTORE_PASSWORD \\ --name testapp \\ --publish mode=host,published=8081,target=8081 \\ testapp:dev  This will start the service (named testapp) within the swarm, and the service will start serving the application similarly to when I used the docker run command above.\nOnce started the following command will return basic information about the service\n$ docker service ls  and this information should look something like the following\nID NAME MODE REPLICAS IMAGE PORTS kjzh1uc2ttng testapp replicated 1/1 testapp:dev  If I want to monitor the activity of the service I should monitor the logs of its associated container and, in order to do this I need to know the container\u0026rsquo;s ID.\nI can issue the following command and note the value in the CONTAINER_ID column for the image testapp:dev and use it to interrogate the logs.\n$ docker container ls  This will return something like the following:\nCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES d5b269d508b4 testapp:dev \u0026quot;/sbin/entrypoint.sh\u0026quot; 15 seconds ago Up 14 seconds 0.0.0.0:8081-\u0026gt;8081/tcp testapp.1.tb4n70oe1t8tz3qdzo2aawmek  And I can view the logs of the running container using as much of the container\u0026rsquo;s ID as necessary to make it unique\n$ docker logs d5b  This allows me to confirm that the application started correctly and is responding to requests.\nAs before, I can point my browser at https://localhost:8081/r/home and exercise the packaged application running as a docker service.\nAfter some activity I can review the history of my interactions (and the server\u0026rsquo;s responses) by once again reviewing the logs:\n$ docker logs d5  To shutdown the service, I run\n$ docker service rm testapp  Review There were quite a number of steps but I hope the detail was illuminative. The repository also contains a Makefile that streamlines building the application and the docker image easier.\nThe following targets are defined:\nclean-all - cleans out all compilation and build artifacts\nclean-build - deletes the ClojureScript and JVM build artifacts. Does not remove any docker build artifacts.\nclean-deploy - deletes the docker build artifacts in ./docker/deploy\nbuild - build the ClojureScript production js file, and the JVM .classes files\ndocker - builds the docker image\ndocker/deploy - assembles all the artifacts needed to build the docker image to the docker/deploy directory, and cleans out any unnecessary files and directories\nrun-local - using the java command runs the application from the application jar in the docker/deploy directory.\n","date":1588867826,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588867826,"objectID":"a45d8c4bce10c3363965d7dbe099dde0","permalink":"https://heykieran.github.io/post/deploy-pedestal-react-to-docker/","publishdate":"2020-05-07T12:10:26-04:00","relpermalink":"/post/deploy-pedestal-react-to-docker/","section":"post","summary":"I will demonstrate how to compile and package a completely operational, but minimal, application comprising a secure Clojure Pedestal API server and a ClojureScript (reagent/reframe) front-end React application; and finally deploy that application to a docker container running as a Docker swarm service with its configuration provided by Docker's secrets functionality.","tags":["clojure","clojurescript","pedestal","react","docker"],"title":"Deploy a Clojure Pedestal API Server \u0026 React/ClojureScript Web Application to Docker","type":"post"},{"authors":["Kieran Owens"],"categories":["Blog Post"],"content":"Passing a \u0026ldquo;Configuration\u0026rdquo; to a Clojure Application Introduction There are many ways to pass configuration values to a Clojure application. This piece will cover four of them:\n  Command Line Parameters  Environment Variables  Dynamic Environment Variables, and  Docker Secrets  The first two are briefly discussed, while greater time is spent on the final two. Of the four, the last is particularly useful to keep secure configuration values that ought to be kept so - passwords, private keys etc.\nUsing Command Line Parameters If one starts Clojure from the command line using the -m option specifying a namespace, Clojure will execute the -main function from that namespace, passing any further arguments on the command line as parameters to -main.\nFor example, the following Clojure code\n(ns main.core) (defn -main [args] (println args))  which can be executed from the command line using\n$ clj -m main.core \u0026quot;Hello World!\u0026quot;  will result in the string Hello World! being printed to the console.\nUsing Environment Variables As an alternative to command line parameters, it\u0026rsquo;s often convenient to have your Clojure application read its parameters from the application\u0026rsquo;s execution environment i.e. environment variables or JVM system properties.\nSo running\n$ export MYARGS=\u0026quot;Hello World!\u0026quot;  at the command line, and changing the -main function to\n(defn -main [\u0026amp; args] (println (System/getenv \u0026quot;MYARGS\u0026quot;)))  you can now run the application using\n$ clj -m main.core  and see the same result.\nThe value of the MYARGS environment variable is read from the environment and then printed to the console.\nUnfortunately, as convenient as this is when executing the code, it can be a little inconvenient during development. If this is the only place you use the variable there\u0026rsquo;s little lost, but if the value is used in other areas of your application e.g. in other namespaces, any changes to its name or expected type will lead to an amount of error-prone \u0026ldquo;code surgery\u0026rdquo;.\nAlso, env variables are, by their nature, strings; so if you need the value as, for instance, an int you\u0026rsquo;ll need to perform the casting and error-checking at the time of initialization.\nUsing \u0026ldquo;Dynamic\u0026rdquo; Environment Variables WalmartLabs have published a Clojure library on GitHub to address many of these issues. The library centralizes the reading of env variables, and also allows for existence-checking, the setting of default values, merging with JVM system properties, casting, type-checking, and composition.\nThe library makes it possible to define in a simple edn file the shape of your configuration data and have it parsed correctly from the environment (and other locations) into the structure you want.\nAs an example, if you have a file called config.edn somewhere on your classpath with\n{:app-configuration {:myargs #dyn/prop MYARGS}}  and change the main/core.clj file to\n(ns main.core (:require [clojure.edn :as edn] [clojure.java.io :as io] [com.walmartlabs.dyn-edn :refer [env-readers]])) (def app-config (-\u0026gt;\u0026gt; \u0026quot;config.edn\u0026quot; io/resource slurp (edn/read-string {:readers (env-readers)}))) (defn -main [\u0026amp; args] (println (get-in app-config [:app-configuration :myargs])))  and then run the application using\n$ clj -m main.core  You\u0026rsquo;ll see the same result - but, the application\u0026rsquo;s configuration has been correctly (and automatically) parsed into a configuration structure and is available as a map named main.core/app-config that can be used throughout your application.\nThe use of the config.edn file also allows you to view the expected configuration parameters, or add to them, or change their default values in one central location - very convenient.\nUsing Docker Secrets - with Dynamic Environment Variables An area where env variables are extensively used as configuration parameters is when an application is being run inside a docker container. By providing one or more -e options to the docker run command, it\u0026rsquo;s possible to establish the configuration environment for the application (if that\u0026rsquo;s where the application expects to find it).\nUnfortunately, certain configuration parameters contain sensitive information, such as passwords or private keys and one can\u0026rsquo;t realistically embed those values in the application\u0026rsquo;s code. They may change frequently; they may need to differ from one container to another; and their very existence in the code represents a risk that they\u0026rsquo;ll \u0026ldquo;leak\u0026rdquo; into an SCM.\nOf course, the use of environment variables is a good alternative to embedded code values, but represents a different, albeit smaller, set of risks. Anyone with access to the docker instance could recover the environment variables passed to a container during initialization.\nIn order to address this, Docker introduced the concept of secrets with docker swarm. Secrets allow sensitive information to be defined securely, and then selectively made available to containers which are running as docker services. It is only within the running container that the secret\u0026rsquo;s value is available as contents of files mounted from an in-memory filesystem, by default at /run/secrets/\u0026lt;secret_name\u0026gt;, where they can be accessed by the application.\nIn order to tie together environment variables with secrets, I\u0026rsquo;ve submitted a PR to the maintainer of the walmart-labs/dyn-edn library which, in addition to env variables and system properties, merges in docker secrets to the set of variable available to the library\u0026rsquo;s readers: #dyn/prop, #dyn/join, #dyn/long, #dyn/boolean, and #dyn/keyword.\n Note The PR was accepted by the maintainer, but the library hasn\u0026rsquo;t yet made it to clojars. In order to use the secrets functionality you\u0026rsquo;ll need to add the following to your :deps entry in deps.edn. This will pull the appropriate version of the code.\n com.walmartlabs/dyn-edn {:git/url \u0026quot;https://github.com/walmartlabs/dyn-edn.git\u0026quot; :sha \u0026quot;855a775959cf1bec531a303a323e6f05f7b260fb\u0026quot;}  Our Example with Secrets To use a docker secret in lieu of the MYARGS env variable used in previous examples all one needs to do is create a secret called MYARGS with the appropriate value\n$ printf \u0026quot;Hello World!\u0026quot; | docker secret create MYARGS -  and, when starting the container as a docker service, authorize the service to use that secret\n$ docker service create --replicas 1 --secret MYARGS --name \u0026lt;svcname\u0026gt; \u0026lt;image containing the app\u0026gt;  No change needs to be made to the config.edn file, or to the source code.\n","date":1588865175,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588865175,"objectID":"3c8487f2b01a3ae253af0157c7f25bdc","permalink":"https://heykieran.github.io/post/clojure-configuration/","publishdate":"2020-05-07T11:26:15-04:00","relpermalink":"/post/clojure-configuration/","section":"post","summary":"A piece that discusses options for passing configuration information to Clojure applications. It covers alternatives ranging from simple command line parameters to the use of Docker secrets.","tags":["clojure","docker"],"title":"Clojure Configurations with Docker Secrets","type":"post"},{"authors":["Kieran Owens"],"categories":["Blog Post"],"content":"Introduction The following are some notes about a repository containing working code (extracted from a larger project) demonstrating a combination of a secured Pedestal website (and associated API services), and a React-ive ClojureScript front-end application that utilizes either Google or bespoke login logic to identify and validate the user\u0026rsquo;s credentials, and sets his/her authorization levels.\nI hope that it may be helpful to anyone else who may know how each of the the individual pieces work, but is wondering how to put it all together.\nI owe a debt of gratitude to Tristan Straub, as much of the front-end logic (and code) to utilize Google\u0026rsquo;s login is based on some code he posted on Github. I\u0026rsquo;ve changed the code in many ways, so any errors are not his but mine.\nThe front-end application, which is intentionally simple, allows a user to login, and according to his/her permissions will allow access to various resources. The application is written using React/ReFrame, Semantic UI React and ClojureScript. The application uses Figwheel-main to compile and, in development mode run the front-end; but switching to a different tool-chain (e.g. shadow-cljs) should be relatively easy.\nFeatures Google Login Integration (and mapping to application id) The application demonstrates how to integrate Google\u0026rsquo;s login functionality with a ClojureScript application. After successfully authenticating with Google, the user\u0026rsquo;s Google email address is associated with one (and only one) internal application user ID. The internal user ID is associated internally with one or more application defined roles, which are defined in the code.\nConceivably, this mapping of external ID to internal ID could allow multiple external authentication services to be used to map multiple externally asserted identities to a single internal user ID. For example, by extending the application to use Facebook\u0026rsquo;s authentication service, it would be possible to have both user@gmail.com and user@facebook.com to be mapped to the same internal user ID, e.g. :user.\nFundamentally, authenticating and logging in merely associates a user with a web session. The session is the operative object and identities are not, and cannot be shared between sessions. A user may have multiple sessions open, but they don\u0026rsquo;t \u0026ldquo;mingle\u0026quot;.\nAd-hoc affirmative login method The application as presented allows a user to simply assert that they are a known user. The only reason this feature is included is to simplify debugging. In a production application these assertions would typically be replaced with an application specific logon process.\nIsolation of sensitive information from codebase In order to run Pedestal/Jetty (for production) or Figwheel/Jetty (for development) with https (required to use Google login) the location of a keystore and its password must be supplied.\nThis is an obvious security concern - including any sensitive information in either the source-code, or the application\u0026rsquo;s generated js code is poor security hygiene. The application avoids this by using environment variable (assumed to be available) to store this information which is read-only at runtime.\nSecured API end-points by role membership The application uses role-based security, where access to resources (URI\u0026rsquo;s) is permitted or prohibited according to whether a user has membership within a particular role. A user ID can be associated with one or more roles. Roles are independent of one another. There is no concept of hierarchy or inheritance beyond how the code chooses to handle these concepts.\nThe application, for our purposes, defines three roles: :admin, :user and :public. An unauthenticated user is associated with the role :public. Note that there is nothing privileged about these roles, or their names. They are completely application defined.\nIn the code for the application\u0026rsquo;s configuration file (common-src/config/config.cljc) you can see how these have been defined:\n(def roles-and-users {:admin {:roles #{:admin} :users #{\u0026quot;admin@timpsongray.com\u0026quot; \u0026quot;heykieran@gmail.com\u0026quot;}} :user {:roles #{:user} :users #{\u0026quot;user@timpsongray.com\u0026quot;}}})  Here, we\u0026rsquo;ve defined two users :user and :admin, along with two roles, also called :user and :admin. Users who authenticated with the email addresses admin@timpsongray.com and heykieran@gmail.com will be associated with the user ID :admin, and the user with the email address user@timpsongray.com will be associated with the user ID :user.\nIf we examine how routes are defined in the file server/be_handler_pdstl.clj we can see how security is applied to URL\u0026rsquo;s.\n(def routes (route/expand-routes #{[\u0026quot;/echo\u0026quot; :get echo] [\u0026quot;/auth/isauthenticated\u0026quot; :post (build-secured-route-vec-to app-auth/get-current-logged-in-user) :route-name :alloc-public/is-authenticated] [\u0026quot;/auth/setid\u0026quot; :post (build-secured-route-vec-to app-auth/alloc-auth-explicitly-set-identity-of-user-post) :route-name :alloc-public/auth-set-id-post] [\u0026quot;/auth/google\u0026quot; :post (build-secured-route-vec-to app-auth/alloc-auth-google-login) :route-name :alloc-public/google-login-post] [\u0026quot;/auth/logout\u0026quot; :post (build-secured-route-vec-to disconnect-session) :route-name :alloc-user/auth-logout-post] [\u0026quot;/api/getsecresource/p\u0026quot; :post (build-secured-route-vec-to get-secured-resource) :route-name :alloc-public/test-res] [\u0026quot;/api/getsecresource/u\u0026quot; :post (build-secured-route-vec-to get-secured-resource) :route-name :alloc-user/test-res] [\u0026quot;/api/getsecresource/a\u0026quot; :post (build-secured-route-vec-to get-secured-resource) :route-name :test-res] [\u0026quot;/r/home\u0026quot; :get [content-neg-intc respond-with-app-page] :route-name :app-main-page]}))  The current implementation uses the namespace of values of each route\u0026rsquo;s :route-name key to assign security.\nAny protected URL whose :route-name namespace is :alloc-public is available to any user, authenticated or not.\nAny protected URL whose :route-name namespace is :alloc-user is available to any user associated with the :user role.\nAny protected URL whose :route-name namespace is either :alloc-admin or the default namespace is available to only users associated with the :admin role.\n URL\u0026rsquo;s are only protected if they use the auth interceptors. These interceptors are included when the function build-secured-route-vec-to is used to wrap the content handler function.\n Another item to note is the three test URL\u0026rsquo;s /api/getsecresource/p (available to all users), /api/getsecresource/u (available to users in the :user role) and /api/getsecresource/a (available only to users in the :admin role) use the same handler get-secured-resource.\nDevelopment Server \u0026amp; Production Server The application has both a development mode and a production mode. Both modes use Pedestal as the API server, responding to requests as defined in the routes parameter used to start the server. The difference between the two modes is in how the js files are served, and in how front-end development proceeds, or not.\nIn development mode the application\u0026rsquo;s js files are served from a handler (fe-src/server/fe-handler) sitting behind figwheel/Jetty, and started using the script provided in scripts/server.clj. This facilitates the standard figwheel development process of having figwheel monitor a set of source directories and regenerate and reload any changed files as necessary. This should be familiar to anyone who\u0026rsquo;s used figwheel-main for ClojureScript development. An alias has been defined in the deps.edn file to start all the various servers and to start figwheel.\nIn production mode, the js files are served from the Pedestal/Jetty server itself. Of course, in order to do this the js files must have been previously compiled by figwheel. An alias has been defined in the deps.edn file for this purpose.\nLog-out Functionality The application allows the user to disassociate their session from their identity. Because the session is the operative object, this is essentially logging out.\nSession Expiration When credentials are issued for an authenticated user and associated with a session, the information will also contain an expiration date. If a user attempts to access a protected resource and the credentials are found to have expired, access is denied and the user\u0026rsquo;s credentials are disassociated from the session. This essentially logs that user out and he/she will need to reassociate their credentials with the session.\nReact/Reagent/Reframe/kee-frame Application The test application is a reactive application written in ClojureScript using reagent, reframe and kee-frame. It illustrates some of the principles required for a simple application of this type.\nSemantic UI Integration The toolkit used for widgets and styling is SemanticUI-react, and the application illustrates how the library can be used.\nRunning the Servers \u0026amp; Applications Setting up a keystore for HTTPS In order to run the web servers in secured mode you\u0026rsquo;ll need to create a keystore for the certificates used by the servers and make it available to Jetty. Instructions on how to do this can be found here.\nSetting up Google Login In order to use the application for yourself you will need to get your own Google Client ID. Instructions on how to do this can be found here.\nYou will also need to use the Google Console to inform Google of the Authorized Javascript Origins associated with your Client ID. These should be the names and ports of your https endpoints. For testing, these will typically be the server name and port of your Pedestal/Jetty and your figwheel/Jetty (for development mode only) servers.\nThe values should also be set in the following places\nIn your environment the following variables should be set\n   Environment Variable Value     ALLOC_KEYSTORE_PASSWORD The keystore\u0026rsquo;s password   ALLOC_KEYSTORE_LOCATION The keystore\u0026rsquo;s filesystem location   ALLOC_SSL_PORT The ssl port number used for Pedestal   ALLOC_PORT The port number used for Pedestal    In the common-src/config/config.cljc you will need to set the following variables\n   Configuration Variable Value     google-client-id your Google Client ID   my-hostname your server\u0026rsquo;s name   figwheel-ssl-port the port used by figwheel\u0026rsquo;s https server and serving the application\u0026rsquo;s js files   pedestal-port Pedestal\u0026rsquo;s HTTP port number (should match ALLOC_PORT).   pedestal-ssl-port Pedestal\u0026rsquo;s HTTPS port number (should match ALLOC_SSL_PORT)   google-callback-url change the server name in this variable to match your server\u0026rsquo;s name.    In the file dev.cljs.edn change the :open-url parameter to match your server\u0026rsquo;s name, and the ssl port used by figwheel. This should match https://\u0026lt;my-hostname\u0026gt;:\u0026lt;pedestal-ssl-port\u0026gt;/r/home.\nStarting the Server(s) Development Mode   In your IDE of choice, start a REPL (with the alias :main)\n  Load and execute the control namespace\n  Execute the function (start-dev) (It\u0026rsquo;s within a comment expression).\n  Log messages are sent to the REPL output stream, so you can monitor progress and activity.\n  When the Pedestal server has started, run the following from a command line\nclj -A:dev  This will start the front-end server used by figwheel on ports 9500 and figwheel-ssl-port and will start the figwheel watch process.\n  Your browser should automatically open to https://\u0026lt;my-hostname\u0026gt;:\u0026lt;figwheel-ssl-port\u0026gt;/r/home where the application will be loaded. (You should have set this in dev.cljs.edn as above).\n   When you\u0026rsquo;re finished and wish to stop the front-end server: from the Figwheel console you issue the :cljs/quit command to stop the Figwheel build process followed by Ctrl+C to stop the front-end server itself.   Production Mode Build the production application by running\nclj -A:prod  from the command line. This will generate the production js files from your ClojureScript sources. Then, from the command line run\nclj -A:main -m control  This will start the Pedestal server which in addition to serving API requests will also serve the js files built in the last step.\nFinally, open your browser and navigate to https://\u0026lt;my-hostname\u0026gt;:8081/r/home to display the application\u0026rsquo;s Home page.\nNavigating the Application The Home Page When the application first starts, you can go to the Home page\n  The initial view of the home page (no logged-in user).   The Application\u0026rsquo;s Menu The application is a SPA with client-side routing and has only a single menu with 5 menu items.\n  The main menu (no logged-in user).    The Home item will take you to the Home page The Users menu item will display the application\u0026rsquo;s Sign-In/Sign-Out page. Here you can connect an identity to your session (log-in), or disconnect an identity from your session (log-out). The Public menu item will request content from an unsecured API endpoint whose content is available to any user whether authenticated or not. The User menu item will request content from an an API endpoint to which access has been restricted to users with role memberships of :admin or :user. The Admin menu item will request content from an an API endpoint to which access has been restricted to users with role membership of :admin.  Access a Public Resource Even though you have not yet signed in, if you click on the Public menu item the application will respond with some content.\n  Access to Public Resource is allowed (no logged-in user).   This is as expected as that resource is unsecured and available to anyone who can access the application.\nSign-In as the :local/:user User On the Sign-In Page, click on the button labelled user@timpsongray.com. This will associate you session with the application user :user, who has been assigned the :user role. This form of sign-in is a :local authority sign-in. The authority is granted by the application itself.\n  The Standard Sign-In Page (no logged-in user).   Once you\u0026rsquo;ve done that you\u0026rsquo;ll be redirected to the Home page where your session and identity details are displayed.\n  After the user :user has signed in.   Accessing a protected resource Now click on the User menu item. The application will attempt to fetch a resource from an API endpoint restricted to users in the :user or :admin roles.\nBecause :user has that role association the contents of the resource is displayed.\n  The user (:user) is allowed to access to the User resource.   However, if you now click on the Admin menu item, which attempts to fetch data from an API endpoint restricted to :admin role members only, you\u0026rsquo;ll see an access denied message.\n  The user (:user) is denied access to the Admin resource.   Sign-Out from :user Click on the Users menu item to go to the Sign-In/Sign-Out page\n  A view of the standard Sign-Out page with user (:user) is logged in.   and at the bottom click on the button in Sign-Out (Local) section. This will remove the identity information from your session, and return you to the Home page.\n  Returned to Home Page after user signs out.   Sign in as a Google User Again, click on the Users menu item to go to the Sign-In/Sign-Out page\n  The Standard Sign-In Page.   This time however click on the Google Sign in button. This will open the familiar Google Sign-In dialog where you can login with your Google identity. If the email address of the Google user is registered with an application user ID your session will assigned that identity, but the :authority will now be :google, indicating that is the entity making the assertion of identity.\n  The Google Sign-In Dialog.   Again, you\u0026rsquo;ll be returned to the Home page where the session\u0026rsquo;s identity information is displayed.\n  The Home Page with Google signed-in user.   Because heykieran@gmail.com is an alias for the user :admin, that is the ID displayed in the top-right corner of the page, and consequently access to the API endpoints restricted to users in the :admin role will be allowed.\nSigning Out If you click on the Users menu item you can return to the Sign-In/Sign-Out page to disconnect your session from the Google account using the Sign Out button. This disconnects your application session, but does not log you out from Google.\n  The Users page with a Signed-In Google user (mapped to application ID :admin).   ","date":1588002788,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588002788,"objectID":"37f4baad1635bb85122b7742e828e506","permalink":"https://heykieran.github.io/post/pedestal-and-google/","publishdate":"2020-04-27T11:53:08-04:00","relpermalink":"/post/pedestal-and-google/","section":"post","summary":"A longer discussion of my publicly available GitHub repository containing a secured Pedestal API server and ClojureScript/React SPA that can use Google login to authenticate a user. I show how to set up HTTPS, integrate with Google and secure API endpoints in the context of a simple React application.","tags":["clojure","clojurescript","pedestal","react","security"],"title":"Pedestal API, ClojureScript SPA and Google Authentication","type":"post"},{"authors":["Kieran Owens"],"categories":["Blog Post"],"content":"Introduction  A repository with some working code and implementation notes can be found here.   I had the occasion recently to investigate, and cursorily evaluate, a number of workflow orchestration systems for use on a project with which I was involved. One of those systems, Cadence, particularly appealed to me - there was something very Clojuresque about it; certainly something very suggestive of a functional language.\nIt has the concept of state durability (in workflow functions) that bears more than a passing resemblance to the persistent data structures of Clojure - but extended across time. This concept, similar to checkpoints, opens avenues to consistent, predictable restarts after failures. If one can restore the complete state of a system to a known good-state then one can continue as if the failure had never occurred. Of course, if system-wide (or even better, distributed) non-volatile RAM ever becomes a reality then Cadence would not be needed. This strikes me as essence of the problem Cadence is attempting to solve, or, at least, the gap it\u0026rsquo;s attempting to bridge. Cadence also allows, through activities, the use of non-persistent data structures which can be considered as being analogous to the concept of a side-effect in Clojure.\nThe separation of the functional from the side-effect-ing, and the elision of infrastructure and communication failure concerns leaves developers with simpler, almost always more tractable, domain logic concerns and significantly reduces the cognitive load. This is similar to the benefits often realized through the adoption of functional languages.\nA Brief Tour to Cadence  Cadence is a workflow automation system developed by Uber. It shares many features with other workflow automation systems but differs by being uniquely fault-oblivious rather than merely fault-tolerant. The approach adopted by Cadence simplifies greatly the work of developers who are relieved of many of the burdens of coordinating activities and recovering from system or service failure.\nCadence is complex but three concepts core to its understanding are\n The Cadence Service itself, Workflow Workers and Activity Workers  The Cadence service, backed by a persistent data-store such as Cassandra or MySql, is responsible for orchestrating the activities of both type of workers, for maintaining history, and in the case of failure, for recovering the state of all workflows (but not activities).\nConceptually, the Cadence service instructs a Workflow Worker to execute a Workflow function. The Workflow function, which implements business logic, is guaranteed by Cadence to be durable. That is, its state, including its thread stack and thread-local variables, are known and stored by Cadence, and in the case of failure they are restored.\nWorkflows, like the business processes they typically model, may be long-running. It\u0026rsquo;s not unusual for a real-world business process to take days or even months to complete, and Cadence provides excellent facilities to support such long-running processes within workflow functions. Therefore, the durability of the workflow functions (with the guaranteed recovery of their states across failures) enables a simple straight-line view of the business logic. This greatly reduces the complexity of the development process by reducing the burden on the developer to anticipate and mitigate all failure modes.\nIn order to be able to guarantee durability across failures Cadence places a number of restrictions on the code in Workflow functions. The code must be deterministic i.e. executing the code must produce the same result no matter how often it is run. Therefore, certain actions are forbidden within workflow code - examples being: interacting directly with external services, getting the time, getting random values, and creating or suspending threads.\nThese type of actions are fundamentally non-deterministic and would make full recovery of the workflow state impossible. However, the Cadence API provides alternatives for some of these that produce deterministic behavior; and which assure the recoverability of the function\u0026rsquo;s local variables, threads and state.\nFor situations requiring interaction with external services (the outside world), Cadence insists that all communication be conducted through Activities, using Activity Workers. Activities do not share with Workflows any of Cadence\u0026rsquo;s requirement that they be deterministic. Essentially anything is allowed in activities and any clean-up after failure becomes the responsibility of the developer rather than the Cadence service.\nConceptually, (but not precisely), a Workflow Worker will start an Activity Worker (or multiple Activity Workers) to interact with the outside world. Examples of an Activity might be interacting with a web-service, getting or saving a record to a database, or awaiting human input, such as a decision. Cadence offers no guarantees about activity state, and that state is not recovered in the case of failures of the Cadence infrastructure i.e. within the Cadence service itself.\nIn order to control a running workflow, or to affect its state, it can be signalled using events delivered by Cadence.\nCadence \u0026amp; Clojure Challenges The signature of the worker registration function is registerWorkflowImplementationTypes(java.lang.Class\u0026lt;?\u0026gt;... workflowImplementationClasses) and in the documentation there is the note\n The reason for registration accepting workflow class, but not the workflow instance is that workflows are stateful and a new instance is created for each workflow execution.\n What\u0026rsquo;s not noted, but implied, is that the constructor for the classes must have zero-arg constructors. This is problematic for Clojure as instance variable declared in deftype will create on constructor taking exactly that number of instance variables as arguments.\nYou might then consider inheritance of the deftype-d class to workaround the zero arg constructor issue leaving a cleaner, more Clojure-esque result.\nHowever, although deftype can create a Java class with the fields you need, by default these fields are immutable; but you could use :volatile-mutable to allow the fields to be settable. Unfortunately, the bigger problem is that the generated class is public final which effectively eliminates the possibility that we could use the class as a base class in gen-class.\nThis might have been helpful as we could define a zero-args constructor in gen-class and then using the :constructors field map that constructor to the base class constructor and then assign default values to the field in the :init method. The fact that the deftype-ed class is final eliminates that approach.\nWorking Cadence \u0026amp; Clojure Code In order to fully investigate using Clojure with Cadence I developed a small set of demos to demonstrate how it works, works around what doesn\u0026rsquo;t, and exercises the result. Very little consideration was given to making the code more idiomatic, at least from a Clojure perspective, or even particularly effective. I only making the repository available as it may prove helpful to others who would like to use Clojure with Cadence.\nThe repository also contains further notes on the implementation and lessons learnt.\nWhat\u0026rsquo;s Next? As time allows I\u0026rsquo;ll probably return to the code, making it more idiomatic. But do let me know if you find it helpful, or share your suggestions for improvement.\n","date":1587568238,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587568238,"objectID":"ea85603ab754bf4e179277cf351907ed","permalink":"https://heykieran.github.io/post/cadence-and-clojure/","publishdate":"2020-04-22T11:10:38-04:00","relpermalink":"/post/cadence-and-clojure/","section":"post","summary":"How to use Clojure with the Cadence Workflow orchestration system. Some background on Cadence, and links to a working code repository with implementation notes.","tags":["clojure","cadence"],"title":"Cadence Workflow and Clojure","type":"post"},{"authors":["Kieran Owens"],"categories":["Blog Post"],"content":"Introduction\nSetting up Pedestal (using Jetty) with HTTPS isn\u0026rsquo;t that difficult, but it is a bit \u0026ldquo;fiddly\u0026rdquo;. Essentially, you\u0026rsquo;ll need a keystore so that Jetty has access to encryption keys and can encrypt pages sent over HTTPS.\nThis post only deals with self-signed certificates, but if you want to use commercially-signed certificates it should work too.\n Just be aware that Jetty is happiest with the pkcs12 format - I\u0026rsquo;ve never got it to work satisfactorily using other formats.   Service Map (Pedestal)\nIn order to run Jetty under Pedestal you\u0026rsquo;ll need to supply a service map. The following service map works for me. You can change it as you need. The important elements in the current context are where Jetty should look for the keystore (keystore-location), the :ssl? key, the :ssl-port and the :security-provider.\nMake sure the provider (Conscrypt) is in your deps.edn file\n (def service-map (let [keystore-location (if (System/getenv \u0026quot;KEYSTORE_LOCATION\u0026quot;) (-\u0026gt; (io/file (System/getenv \u0026quot;KEYSTORE_LOCATION\u0026quot;)) (.getCanonicalPath)) \u0026quot;/home/user/security/jetty-keystore\u0026quot;)] {::http/host \u0026quot;0.0.0.0\u0026quot; ::http/allowed-origins {:allowed-origins (fn[_] true) :creds true} ::http/routes #(deref #'routes) ::http/type :jetty ::http/container-options {:context-configurator jetty-websocket-configurator :h2c? true :h2 true :ssl? true :ssl-port 8081 :keystore keystore-location :key-password \u0026quot;thepassword\u0026quot; :security-provider \u0026quot;Conscrypt\u0026quot;} ::http/port 8080}))  Jetty Keystore\nIn order for Pedestal to start with Jetty, it expects to find a keystore in a particular location (see Service Map notes above).\nTo create the keystore (I\u0026rsquo;ve plagiarized/assembled from the following pieces of information web, and I\u0026rsquo;m afraid I can\u0026rsquo;t remember the source(s).)\nGenerate a private site key (site.key)\n$ openssl genrsa -des3 -out site.key 2048  Make a copy of site.key and strip the password, so that it can be auto-loaded\n$ cp site.key site.orig.key $ openssl rsa -in site.orig.key -out site.key  Generate a self-signed signing request (site.csr)\n$ openssl req -new -key site.key -out site.csr  Generate a self-signed certificate (sitex509.crt - in x509 format for loading into the keystore)\n$ openssl req -new -x509 -key site.key -out sitex509.crt  Combine the self-signed certificate (sitex509.crt) and site key (site.key) and export it in pkcs12 format (site.pkcs12)\n$ openssl pkcs12 -inkey site.key -in sitex509.crt -export -out site.pkcs12  Rename the keystore (site.pkcs12) to jetty-keystore\nand adjust the service-map to use it\n","date":1587145177,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587145177,"objectID":"caa521ff1fb0576fd01e59f1ba4c95e2","permalink":"https://heykieran.github.io/post/pedestal-jetty-https/","publishdate":"2020-04-17T13:39:37-04:00","relpermalink":"/post/pedestal-jetty-https/","section":"post","summary":"Introduction\nSetting up Pedestal (using Jetty) with HTTPS isn\u0026rsquo;t that difficult, but it is a bit \u0026ldquo;fiddly\u0026rdquo;. Essentially, you\u0026rsquo;ll need a keystore so that Jetty has access to encryption keys and can encrypt pages sent over HTTPS.","tags":["clojure","pedestal","https"],"title":"Setting-up Pedestal/Jetty with HTTPS","type":"post"}]